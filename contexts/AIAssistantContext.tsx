import React, { createContext, useContext, useState } from 'react';
import { useLanguage } from './LanguageContext';
import { useSoundDetection } from './SoundDetectionContext';
import { useMLModel } from './MLModelContext';

interface AIResponse {
  text: string;
  suggestions?: string[];
  actions?: Array<{
    label: string;
    action: () => void;
  }>;
}

interface AIAssistantContextType {
  generateResponse: (query: string) => Promise<AIResponse>;
  isProcessing: boolean;
}

const AIAssistantContext = createContext<AIAssistantContextType | undefined>(undefined);

export function AIAssistantProvider({ children }: { children: React.ReactNode }) {
  const { currentLanguage, t } = useLanguage();
  const { detections } = useSoundDetection();
  const { modelSettings, modelPerformance } = useMLModel();
  const [isProcessing, setIsProcessing] = useState(false);

  const knowledgeBase = {
    en: {
      patterns: {
        'how.*work|working|function': {
          response: `SoundAware uses advanced TensorFlow Lite machine learning models to analyze audio patterns in real-time. Here's how it works:

ЁЯза **AI Processing**: The app processes audio using a neural network trained on 25+ household sounds
ЁЯФК **Real-time Analysis**: Audio is analyzed in chunks of ${modelSettings.maxDuration} seconds with ${modelSettings.sampleRate}Hz sample rate
ЁЯУК **Confidence Scoring**: Each detection gets a confidence score (currently set to ${Math.round(modelSettings.confidenceThreshold * 100)}% minimum)
ЁЯФТ **Local Processing**: All analysis happens on your device - no data leaves your phone

The model achieves ${Math.round(modelPerformance.accuracy * 100)}% accuracy with ${modelPerformance.inferenceTime}ms inference time.`,
          suggestions: ['What sounds can it detect?', 'How to improve accuracy?', 'Privacy and security?']
        },
        'sound.*detect|what.*sound|which.*sound': {
          response: `SoundAware can detect 25+ household sounds across different categories:

ЁЯПа **Kitchen Sounds**: Microwave beep, kitchen timer, boiling water, blender, coffee maker, dishwasher
ЁЯФФ **Security Alerts**: Doorbell, door knock, window break, car alarm, motion sensor beep
ЁЯПа **Appliances**: Washing machine, vacuum cleaner, air conditioner, dryer cycle, garbage disposal
ЁЯРХ **Pet Sounds**: Dog bark, cat meow, bird chirping, hamster wheel
ЁЯЪи **Emergency**: Smoke alarm, carbon monoxide alarm, fire alarm, security siren
ЁЯУ▒ **Communication**: Phone ring, text message notification, video call ring
ЁЯМК **Ambient**: Running water, footsteps, door closing, chair moving, paper rustling

Current detection stats: ${detections.length} total detections with ${detections.length > 0 ? Math.round(detections.reduce((sum, d) => sum + d.confidence, 0) / detections.length * 100) : 0}% average confidence.`,
          suggestions: ['How accurate is detection?', 'Can I upload audio files?', 'Real-time monitoring?']
        },
        'accura.*|precision|reliable': {
          response: `SoundAware's accuracy depends on several factors:

ЁЯУИ **Overall Performance**:
- Model Accuracy: ${Math.round(modelPerformance.accuracy * 100)}%
- Precision: ${Math.round(modelPerformance.precision * 100)}%
- F1 Score: ${Math.round(modelPerformance.f1Score * 100)}%
- Average Inference Time: ${modelPerformance.inferenceTime}ms

ЁЯОп **Confidence Levels**:
- 90-100%: Extremely reliable
- 80-89%: Highly reliable  
- 70-79%: Good reliability
- 60-69%: Moderate reliability
- Below 60%: May need verification

ЁЯФз **Current Settings**:
- Sensitivity: ${Math.round(modelSettings.sensitivity * 100)}%
- Confidence Threshold: ${Math.round(modelSettings.confidenceThreshold * 100)}%
- Preprocessing: ${modelSettings.enablePreprocessing ? 'Enabled' : 'Disabled'}

**Tips to improve accuracy**: Record in quiet environments, hold device close to sound source, ensure 3-10 second recordings.`,
          suggestions: ['How to improve accuracy?', 'What affects detection?', 'Model settings?']
        },
        'privacy|security|safe|data': {
          response: `SoundAware prioritizes your privacy and security:

ЁЯФТ **Complete Privacy**:
- All audio processing happens locally on your device
- No audio data is ever sent to external servers
- No cloud storage or remote analysis
- Your recordings stay on your device only

ЁЯЫбя╕П **Security Features**:
- Local TensorFlow Lite model execution
- No internet connection required for detection
- Encrypted local storage for settings and history
- No user accounts or data collection

ЁЯУ▒ **Data Control**:
- You can delete detection history anytime
- Audio recordings are stored temporarily and can be removed
- Export your data as CSV for backup
- Complete control over your information

**Your audio never leaves your device - guaranteed!**`,
          suggestions: ['How does local processing work?', 'Can I export my data?', 'Storage management?']
        },
        'upload.*file|file.*upload|import.*audio': {
          response: `Yes! SoundAware supports audio file upload and analysis:

ЁЯУБ **Supported Formats**:
- MP3 (most common)
- WAV (high quality)
- M4A (Apple format)
- AAC (compressed)
- FLAC (lossless)

ЁЯУП **File Requirements**:
- Maximum size: 50MB
- Duration: Up to ${modelSettings.maxDuration} seconds recommended
- Quality: Higher quality = better detection

ЁЯФД **How to Upload**:
1. Go to Record tab
2. Tap "Choose File" button
3. Select audio file from your device
4. Wait for analysis (usually 1-3 seconds)
5. View results with confidence scores

The same ML model processes uploaded files with identical accuracy to live recordings.`,
          suggestions: ['What file formats work best?', 'File size limits?', 'Processing time?']
        },
        'real.*time|live|instant': {
          response: `SoundAware provides true real-time audio analysis:

тЪб **Performance Metrics**:
- Detection Latency: ${modelPerformance.inferenceTime}ms
- Processing Speed: Real-time (no delays)
- Buffer Size: ${modelSettings.batchSize} samples
- Sample Rate: ${modelSettings.sampleRate}Hz

ЁЯФД **Real-time Features**:
- Continuous audio monitoring
- Instant sound classification
- Live audio visualization
- Immediate notifications for important sounds
- Background processing capability

тЪЩя╕П **Optimization**:
- Efficient ML model (${Math.round(modelPerformance.accuracy * 100)}% accuracy)
- Battery-optimized processing
- Minimal CPU usage
- Smart audio buffering

The app can detect and classify sounds within 1-2 seconds of occurrence!`,
          suggestions: ['Battery usage?', 'Background monitoring?', 'Performance optimization?']
        },
        'help|support|how.*use|tutorial': {
          response: `Welcome to SoundAware! Here's your complete guide:

ЁЯУ▒ **Main Features**:

1я╕ПтГг **Home Tab**: Overview of recent detections and quick stats
2я╕ПтГг **Record Tab**: Live recording and file upload for analysis  
3я╕ПтГг **History Tab**: View all past detections, export CSV, share summaries
4я╕ПтГг **Notifications**: Alerts for important sound detections
5я╕ПтГг **AI Chat**: Ask questions about the app (you're here!)
6я╕ПтГг **Settings**: Customize sensitivity, language, and model settings

ЁЯОп **Quick Start**:
- Tap Record tab тЖТ Tap microphone тЖТ Let it listen for 3-10 seconds
- Or upload an audio file for instant analysis
- Check History for all your detections
- Adjust sensitivity in Settings for better results

ЁЯУК **Current Status**: ${detections.length} detections recorded, ${Math.round(modelSettings.sensitivity * 100)}% sensitivity`,
          suggestions: ['Recording tips?', 'Best practices?', 'Troubleshooting?']
        },
        'battery|power|consumption': {
          response: `SoundAware is optimized for minimal battery usage:

ЁЯФЛ **Battery Optimization**:
- Efficient TensorFlow Lite model (only ${modelPerformance.inferenceTime}ms per inference)
- Smart audio buffering to reduce CPU usage
- Background processing optimization
- Automatic sleep mode when inactive

тЪЩя╕П **Power Management**:
- Audio preprocessing: ${modelSettings.enablePreprocessing ? 'Enabled (slight battery impact)' : 'Disabled (battery optimized)'}
- Batch processing: ${modelSettings.batchSize} samples (optimized for efficiency)
- Sample rate: ${modelSettings.sampleRate}Hz (balanced quality/power)

ЁЯТб **Battery Tips**:
- Use lower sensitivity for longer battery life
- Disable preprocessing if not needed
- Enable auto-recording only when necessary
- Close app when not actively monitoring

Typical usage: 2-5% battery per hour of continuous monitoring.`,
          suggestions: ['Power saving tips?', 'Background usage?', 'Optimization settings?']
        },
        'improve.*accuracy|better.*detection|enhance': {
          response: `Here are proven ways to improve detection accuracy:

ЁЯОп **Recording Best Practices**:
- Hold device 1-3 feet from sound source
- Record in quiet environment (minimize background noise)
- Ensure 3-10 second recordings for best results
- Avoid covering microphone

тЪЩя╕П **Optimal Settings** (Current vs Recommended):
- Sensitivity: ${Math.round(modelSettings.sensitivity * 100)}% (try 70-80% for balanced results)
- Confidence Threshold: ${Math.round(modelSettings.confidenceThreshold * 100)}% (60-70% recommended)
- Preprocessing: ${modelSettings.enablePreprocessing ? 'тЬЕ Enabled' : 'тЭМ Disabled'} (enable for better accuracy)
- Postprocessing: ${modelSettings.enablePostprocessing ? 'тЬЕ Enabled' : 'тЭМ Disabled'} (enable for cleaner results)

ЁЯФз **Advanced Optimization**:
- Use higher sample rate (44.1kHz) for complex sounds
- Enable both preprocessing and postprocessing
- Adjust batch size based on device performance

Would you like me to suggest optimal settings for your use case?`,
          suggestions: ['Optimal settings for my device?', 'Troubleshoot poor detection?', 'Advanced configuration?']
        },
        'language|translate|multilingual': {
          response: `SoundAware supports 8 languages with full UI translation:

ЁЯМН **Available Languages**:
- English (English)
- рд╣рд┐рдВрджреА (Hindi) 
- рикрй░риЬри╛римрйА (Punjabi)
- ркЧрлБркЬрк░рк╛ркдрлА (Gujarati)
- родрооро┐ро┤рпН (Tamil)
- р░др▒Жр░▓р▒Бр░Чр▒Б (Telugu)
- ржмрж╛ржВрж▓рж╛ (Bengali)
- рдорд░рд╛рдареА (Marathi)

ЁЯФД **Language Features**:
- Complete UI translation
- Voice assistant in your language
- AI responses in selected language
- Localized date/time formats
- Cultural sound preferences

ЁЯУ▒ **How to Change Language**:
1. Go to Settings tab
2. Tap on Language section
3. Select your preferred language
4. App will restart with new language

Current language: ${currentLanguage === 'en' ? 'English' : currentLanguage === 'hi' ? 'рд╣рд┐рдВрджреА' : currentLanguage === 'pa' ? 'рикрй░риЬри╛римрйА' : currentLanguage}`,
          suggestions: ['Voice commands in my language?', 'Add new language?', 'Translation accuracy?']
        },
        'export|csv|download|backup': {
          response: `SoundAware offers comprehensive data export options:

ЁЯУК **CSV Export Features**:
- Complete detection history with timestamps
- Confidence scores and sound types
- Duration and metadata for each detection
- Automatic filename with date
- Compatible with Excel, Google Sheets

ЁЯУ▒ **Export Process**:
1. Go to History tab
2. Tap "Export CSV" button
3. File downloads automatically (web) or opens share dialog (mobile)
4. Data includes: Date, Time, Sound Type, Confidence %, Duration

ЁЯУд **Share Options**:
- Quick summary with recent detections
- Statistical overview
- Formatted for messaging apps
- Email-friendly format

ЁЯУИ **Your Current Data**:
- Total detections: ${detections.length}
- Average confidence: ${detections.length > 0 ? Math.round(detections.reduce((sum, d) => sum + d.confidence, 0) / detections.length * 100) : 0}%
- Date range: ${detections.length > 0 ? `${detections[detections.length - 1]?.timestamp.toLocaleDateString()} to ${detections[0]?.timestamp.toLocaleDateString()}` : 'No data yet'}`,
          suggestions: ['How to backup data?', 'Share with others?', 'Data formats?']
        }
      },
      fallback: `I'm your AI assistant for SoundAware! I can help you with:

ЁЯОп **App Features**: Recording, detection history, settings, notifications
ЁЯФз **Technical Support**: Model configuration, accuracy optimization, troubleshooting  
ЁЯУК **Data Management**: Export options, sharing, privacy settings
ЁЯМН **Languages**: Multi-language support and voice commands
ЁЯФТ **Privacy**: Local processing, security features, data control

**Current App Status**:
- Detections: ${detections.length} total
- Model accuracy: ${Math.round(modelPerformance.accuracy * 100)}%
- Language: ${currentLanguage}
- Sensitivity: ${Math.round(modelSettings.sensitivity * 100)}%

What would you like to know more about?`
    },
    hi: {
      patterns: {
        'рдХреИрд╕реЗ.*рдХрд╛рдо|рдХрд╛рд░реНрдп.*рдХреИрд╕реЗ|рдлрдВрдХреНрд╢рди': {
          response: `SoundAware рдЙрдиреНрдирдд TensorFlow Lite рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд░рд┐рдпрд▓-рдЯрд╛рдЗрдо рдореЗрдВ рдСрдбрд┐рдпреЛ рдкреИрдЯрд░реНрди рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рддрд╛ рд╣реИ:

ЁЯза **AI рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг**: рдРрдк 25+ рдШрд░реЗрд▓реВ рдзреНрд╡рдирд┐рдпреЛрдВ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдиреНрдпреВрд░рд▓ рдиреЗрдЯрд╡рд░реНрдХ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ
ЁЯФК **рд░рд┐рдпрд▓-рдЯрд╛рдЗрдо рд╡рд┐рд╢реНрд▓реЗрд╖рдг**: ${modelSettings.maxDuration} рд╕реЗрдХрдВрдб рдХреЗ рдЪрдВрдХ рдореЗрдВ ${modelSettings.sampleRate}Hz рд╕реИрдВрдкрд▓ рд░реЗрдЯ рдХреЗ рд╕рд╛рде
ЁЯУК **рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрдХреЛрд░рд┐рдВрдЧ**: рдкреНрд░рддреНрдпреЗрдХ рдкрд╣рдЪрд╛рди рдХреЛ рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрдХреЛрд░ рдорд┐рд▓рддрд╛ рд╣реИ (рд╡рд░реНрддрдорд╛рди рдореЗрдВ ${Math.round(modelSettings.confidenceThreshold * 100)}% рдиреНрдпреВрдирддрдо)
ЁЯФТ **рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг**: рд╕рднреА рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЖрдкрдХреЗ рдбрд┐рд╡рд╛рдЗрд╕ рдкрд░ рд╣реЛрддрд╛ рд╣реИ

рдореЙрдбрд▓ ${Math.round(modelPerformance.accuracy * 100)}% рд╕рдЯреАрдХрддрд╛ рдХреЗ рд╕рд╛рде ${modelPerformance.inferenceTime}ms рдореЗрдВ рдкрд░рд┐рдгрд╛рдо рджреЗрддрд╛ рд╣реИред`,
          suggestions: ['рдХреМрди рд╕реА рдЖрд╡рд╛рдЬреЗрдВ рдкрд╣рдЪрд╛рди рд╕рдХрддрд╛ рд╣реИ?', 'рд╕рдЯреАрдХрддрд╛ рдХреИрд╕реЗ рдмрдврд╝рд╛рдПрдВ?', 'рдЧреЛрдкрдиреАрдпрддрд╛ рдФрд░ рд╕реБрд░рдХреНрд╖рд╛?']
        },
        'рдЖрд╡рд╛рдЬ.*рдкрд╣рдЪрд╛рди|рдзреНрд╡рдирд┐.*рдкрддрд╛|рдХреМрди.*рдЖрд╡рд╛рдЬ': {
          response: `SoundAware 25+ рдШрд░реЗрд▓реВ рдзреНрд╡рдирд┐рдпреЛрдВ рдХреА рдкрд╣рдЪрд╛рди рдХрд░ рд╕рдХрддрд╛ рд╣реИ:

ЁЯПа **рд░рд╕реЛрдИ рдХреА рдЖрд╡рд╛рдЬреЗрдВ**: рдорд╛рдЗрдХреНрд░реЛрд╡реЗрд╡ рдмреАрдк, рдХрд┐рдЪрди рдЯрд╛рдЗрдорд░, рдЙрдмрд▓рддрд╛ рдкрд╛рдиреА, рдмреНрд▓реЗрдВрдбрд░, рдХреЙрдлреА рдореЗрдХрд░
ЁЯФФ **рд╕реБрд░рдХреНрд╖рд╛ рдЕрд▓рд░реНрдЯ**: рдбреЛрд░рдмреЗрд▓, рджрд░рд╡рд╛рдЬрд╛ рдЦрдЯрдЦрдЯрд╛рдирд╛, рдЦрд┐рдбрд╝рдХреА рдЯреВрдЯрдирд╛, рдХрд╛рд░ рдЕрд▓рд╛рд░реНрдо
ЁЯПа **рдЙрдкрдХрд░рдг**: рд╡рд╛рд╢рд┐рдВрдЧ рдорд╢реАрди, рд╡реИрдХреНрдпреВрдо рдХреНрд▓реАрдирд░, рдПрдпрд░ рдХрдВрдбреАрд╢рдирд░, рдбреНрд░рд╛рдпрд░
ЁЯРХ **рдкрд╛рд▓рддреВ рдЬрд╛рдирд╡рд░**: рдХреБрддреНрддреЗ рдХрд╛ рднреМрдВрдХрдирд╛, рдмрд┐рд▓реНрд▓реА рдХрд╛ рдореНрдпрд╛рдКрдВ, рдкрдХреНрд╖рд┐рдпреЛрдВ рдХрд╛ рдЪрд╣рдЪрд╣рд╛рдирд╛
ЁЯЪи **рдЖрдкрд╛рддрдХрд╛рд▓**: рд╕реНрдореЛрдХ рдЕрд▓рд╛рд░реНрдо, рдХрд╛рд░реНрдмрди рдореЛрдиреЛрдСрдХреНрд╕рд╛рдЗрдб рдЕрд▓рд╛рд░реНрдо, рдлрд╛рдпрд░ рдЕрд▓рд╛рд░реНрдо
ЁЯУ▒ **рд╕рдВрдЪрд╛рд░**: рдлреЛрди рд░рд┐рдВрдЧ, рдореИрд╕реЗрдЬ рдиреЛрдЯрд┐рдлрд┐рдХреЗрд╢рди, рд╡реАрдбрд┐рдпреЛ рдХреЙрд▓

рд╡рд░реНрддрдорд╛рди рдЖрдВрдХрдбрд╝реЗ: ${detections.length} рдХреБрд▓ рдкрд╣рдЪрд╛рди, ${detections.length > 0 ? Math.round(detections.reduce((sum, d) => sum + d.confidence, 0) / detections.length * 100) : 0}% рдФрд╕рдд рд╡рд┐рд╢реНрд╡рд╛рд╕ред`,
          suggestions: ['рд╕рдЯреАрдХрддрд╛ рдХреИрд╕реА рд╣реИ?', 'рдлрд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ?', 'рд░рд┐рдпрд▓-рдЯрд╛рдЗрдо рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ?']
        },
        'рд╕рдЯреАрдХрддрд╛|рдкрд░рд┐рд╢реБрджреНрдзрддрд╛|рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп': {
          response: `SoundAware рдХреА рд╕рдЯреАрдХрддрд╛ рдХрдИ рдХрд╛рд░рдХреЛрдВ рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░рддреА рд╣реИ:

ЁЯУИ **рд╕рдордЧреНрд░ рдкреНрд░рджрд░реНрд╢рди**:
- рдореЙрдбрд▓ рд╕рдЯреАрдХрддрд╛: ${Math.round(modelPerformance.accuracy * 100)}%
- рдкрд░рд┐рд╢реБрджреНрдзрддрд╛: ${Math.round(modelPerformance.precision * 100)}%
- F1 рд╕реНрдХреЛрд░: ${Math.round(modelPerformance.f1Score * 100)}%
- рдФрд╕рдд рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рд╕рдордп: ${modelPerformance.inferenceTime}ms

ЁЯОп **рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрддрд░**:
- 90-100%: рдЕрддреНрдпрдзрд┐рдХ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп
- 80-89%: рдЕрддреНрдпрдзрд┐рдХ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп
- 70-79%: рдЕрдЪреНрдЫреА рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛
- 60-69%: рдордзреНрдпрдо рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛

ЁЯФз **рд╡рд░реНрддрдорд╛рди рд╕реЗрдЯрд┐рдВрдЧреНрд╕**:
- рд╕рдВрд╡реЗрджрдирд╢реАрд▓рддрд╛: ${Math.round(modelSettings.sensitivity * 100)}%
- рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реАрдорд╛: ${Math.round(modelSettings.confidenceThreshold * 100)}%

**рд╕рдЯреАрдХрддрд╛ рдмрдврд╝рд╛рдиреЗ рдХреЗ рдЯрд┐рдкреНрд╕**: рд╢рд╛рдВрдд рд╡рд╛рддрд╛рд╡рд░рдг рдореЗрдВ рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ, рдбрд┐рд╡рд╛рдЗрд╕ рдХреЛ рдзреНрд╡рдирд┐ рд╕реНрд░реЛрдд рдХреЗ рдкрд╛рд╕ рд░рдЦреЗрдВред`,
          suggestions: ['рд╕рдЯреАрдХрддрд╛ рдХреИрд╕реЗ рдмрдврд╝рд╛рдПрдВ?', 'рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХреИрд╕реЗ рдмрджрд▓реЗрдВ?', 'рдмреЗрд╣рддрд░ рдкрд░рд┐рдгрд╛рдо рдХреИрд╕реЗ рдкрд╛рдПрдВ?']
        }
      },
      fallback: `рдореИрдВ SoundAware рдХрд╛ AI рд╕рд╣рд╛рдпрдХ рд╣реВрдВ! рдореИрдВ рдЖрдкрдХреА рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ:

ЁЯОп **рдРрдк рд╕реБрд╡рд┐рдзрд╛рдПрдВ**: рд░рд┐рдХреЙрд░реНрдбрд┐рдВрдЧ, рдкрд╣рдЪрд╛рди рдЗрддрд┐рд╣рд╛рд╕, рд╕реЗрдЯрд┐рдВрдЧреНрд╕, рд╕реВрдЪрдирд╛рдПрдВ
ЁЯФз **рддрдХрдиреАрдХреА рд╕рд╣рд╛рдпрддрд╛**: рдореЙрдбрд▓ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди, рд╕рдЯреАрдХрддрд╛ рдЕрдиреБрдХреВрд▓рди
ЁЯУК **рдбреЗрдЯрд╛ рдкреНрд░рдмрдВрдзрди**: рдирд┐рд░реНрдпрд╛рдд рд╡рд┐рдХрд▓реНрдк, рд╕рд╛рдЭрд╛рдХрд░рдг, рдЧреЛрдкрдиреАрдпрддрд╛
ЁЯМН **рднрд╛рд╖рд╛рдПрдВ**: рдмрд╣реБрднрд╛рд╖реА рд╕рдорд░реНрдерди рдФрд░ рдЖрд╡рд╛рдЬ рдХрдорд╛рдВрдб

**рд╡рд░реНрддрдорд╛рди рдРрдк рд╕реНрдерд┐рддрд┐**:
- рдкрд╣рдЪрд╛рди: ${detections.length} рдХреБрд▓
- рдореЙрдбрд▓ рд╕рдЯреАрдХрддрд╛: ${Math.round(modelPerformance.accuracy * 100)}%
- рд╕рдВрд╡реЗрджрдирд╢реАрд▓рддрд╛: ${Math.round(modelSettings.sensitivity * 100)}%

рдЖрдк рдХреНрдпрд╛ рдЬрд╛рдирдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ?`
    }
  };

  const generateResponse = async (query: string): Promise<AIResponse> => {
    setIsProcessing(true);
    
    // Simulate processing time
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 1500));
    
    try {
      const language = knowledgeBase[currentLanguage as keyof typeof knowledgeBase] || knowledgeBase.en;
      const queryLower = query.toLowerCase();
      
      // Find matching pattern
      for (const [pattern, response] of Object.entries(language.patterns)) {
        const regex = new RegExp(pattern, 'i');
        if (regex.test(queryLower)) {
          setIsProcessing(false);
          return {
            text: response.response,
            suggestions: response.suggestions
          };
        }
      }
      
      // Fallback response
      setIsProcessing(false);
      return {
        text: language.fallback,
        suggestions: ['How does it work?', 'What sounds can it detect?', 'Help and support?']
      };
    } catch (error) {
      setIsProcessing(false);
      return {
        text: currentLanguage === 'hi' 
          ? 'рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдореБрдЭреЗ рдЖрдкрдХрд╛ рдкреНрд░рд╢реНрди рд╕рдордЭрдиреЗ рдореЗрдВ рдХрдард┐рдирд╛рдИ рд╣реЛ рд░рд╣реА рд╣реИред рдХреГрдкрдпрд╛ рджреВрд╕рд░реЗ рддрд░реАрдХреЗ рд╕реЗ рдкреВрдЫреЗрдВред'
          : 'I apologize, but I\'m having trouble understanding your question. Could you please rephrase it?',
        suggestions: ['How does it work?', 'What sounds can it detect?', 'Help and support?']
      };
    }
  };

  return (
    <AIAssistantContext.Provider value={{
      generateResponse,
      isProcessing,
    }}>
      {children}
    </AIAssistantContext.Provider>
  );
}

export function useAIAssistant() {
  const context = useContext(AIAssistantContext);
  if (context === undefined) {
    throw new Error('useAIAssistant must be used within a AIAssistantProvider');
  }
  return context;
}